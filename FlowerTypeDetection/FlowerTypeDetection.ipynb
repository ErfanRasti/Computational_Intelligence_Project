{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Flower Type Detection\n","## Importing Libraries"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:54:32.729183Z","iopub.status.busy":"2023-01-01T15:54:32.728084Z","iopub.status.idle":"2023-01-01T15:54:32.735873Z","shell.execute_reply":"2023-01-01T15:54:32.734305Z","shell.execute_reply.started":"2023-01-01T15:54:32.729127Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version 2.4.1\n"]}],"source":["import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from kaggle_datasets import KaggleDatasets\n","print(\"Tensorflow version \" + tf.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["## Setting up the TPU"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:06.397194Z","iopub.status.busy":"2023-01-01T15:49:06.396815Z","iopub.status.idle":"2023-01-01T15:49:11.242470Z","shell.execute_reply":"2023-01-01T15:49:11.241601Z","shell.execute_reply.started":"2023-01-01T15:49:06.397166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on TPU  grpc://10.0.0.2:8470\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-01 15:49:06.405117: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2023-01-01 15:49:06.408248: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2023-01-01 15:49:06.408284: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","2023-01-01 15:49:06.408387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3f10461d28be): /proc/driver/nvidia/version does not exist\n","2023-01-01 15:49:06.411849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-01 15:49:06.413718: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2023-01-01 15:49:06.448555: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-01 15:49:06.448617: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n","2023-01-01 15:49:06.466653: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-01 15:49:06.466710: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n","2023-01-01 15:49:06.468807: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n"]},{"name":"stdout","output_type":"stream","text":["REPLICAS:  8\n"]}],"source":["# Detect TPU, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy() \n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing the data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.243989Z","iopub.status.busy":"2023-01-01T15:49:11.243772Z","iopub.status.idle":"2023-01-01T15:49:11.635236Z","shell.execute_reply":"2023-01-01T15:49:11.634585Z","shell.execute_reply.started":"2023-01-01T15:49:11.243964Z"},"trusted":true},"outputs":[],"source":["GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.638412Z","iopub.status.busy":"2023-01-01T15:49:11.637638Z","iopub.status.idle":"2023-01-01T15:49:11.908973Z","shell.execute_reply":"2023-01-01T15:49:11.908061Z","shell.execute_reply.started":"2023-01-01T15:49:11.638371Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-01 15:49:11.646869: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-01 15:49:11.730358: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-01 15:49:11.807818: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"]}],"source":["EPOCHS = 100\n","BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n","\n","\n","IMAGE_SIZE = [192, 192]\n","GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-192x192'\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n","VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n","TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.911688Z","iopub.status.busy":"2023-01-01T15:49:11.911402Z","iopub.status.idle":"2023-01-01T15:49:12.097593Z","shell.execute_reply":"2023-01-01T15:49:12.096776Z","shell.execute_reply.started":"2023-01-01T15:49:11.911661Z"},"trusted":true},"outputs":[],"source":["def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n","    return image\n","\n","def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n","    }\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class'], tf.int32)\n","    return image, label # returns a dataset of (image, label) pairs\n","\n","def read_unlabeled_tfrecord(example):\n","    UNLABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n","        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n","    }\n","    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    idnum = example['id']\n","    return image, idnum # returns a dataset of image(s)\n","\n","def load_dataset(filenames, labeled=True, ordered=False):\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","\n","    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset\n","\n","def get_training_dataset():\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","def get_validation_dataset():\n","    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=False)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    return dataset\n","\n","def get_test_dataset(ordered=False):\n","    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","training_dataset = get_training_dataset()\n","validation_dataset = get_validation_dataset()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:12.098955Z","iopub.status.busy":"2023-01-01T15:49:12.098755Z","iopub.status.idle":"2023-01-01T15:49:12.108471Z","shell.execute_reply":"2023-01-01T15:49:12.107617Z","shell.execute_reply.started":"2023-01-01T15:49:12.098932Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"]}],"source":["def count_data_items(filenames):\n","    # the number of data items is written in the name of the .tfrec\n","    # files, i.e. flowers00-230.tfrec = 230 data items\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)\n","\n","NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n","NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:33.738770Z","iopub.status.busy":"2023-01-01T15:49:33.738471Z","iopub.status.idle":"2023-01-01T15:49:36.926398Z","shell.execute_reply":"2023-01-01T15:49:36.925498Z","shell.execute_reply.started":"2023-01-01T15:49:33.738743Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data batch shape: (256, 192, 192, 3)\n","labels batch shape: (256,)\n"]}],"source":["for data_batch, labels_batch in training_dataset:\n","    print(\"data batch shape:\", data_batch.shape)\n","    \n","    print(\"labels batch shape:\", labels_batch.shape)\n","    break\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":4}
