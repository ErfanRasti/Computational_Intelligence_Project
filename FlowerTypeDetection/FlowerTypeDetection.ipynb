{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Flower Type Detection"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Downloading the dataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/bin/zsh: /home/erfan/anaconda3/envs/tensorflow/lib/libtinfo.so.6: no version information available (required by /usr/bin/zsh)\n","^C\n","User cancelled operation\n"]}],"source":["# from google.colab import files\n","# files.upload()\n","\n","# !mkdir -p ~/.kaggle\n","# !cp kaggle.json ~/.kaggle/\n","# !chmod 600 ~/.kaggle/kaggle.json\n","\n","# ! kaggle competitions download -c tpu-getting-started\n","# ! unzip tpu-getting-started.zip -d ./data/tpu-getting-started\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:54:32.729183Z","iopub.status.busy":"2023-01-01T15:54:32.728084Z","iopub.status.idle":"2023-01-01T15:54:32.735873Z","shell.execute_reply":"2023-01-01T15:54:32.734305Z","shell.execute_reply.started":"2023-01-01T15:54:32.729127Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-10 14:21:30.177089: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"]},{"name":"stdout","output_type":"stream","text":["Tensorflow version 2.9.0\n"]}],"source":["import re\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","print(\"Tensorflow version \" + tf.__version__)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Setting up the TPU"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:06.397194Z","iopub.status.busy":"2023-01-01T15:49:06.396815Z","iopub.status.idle":"2023-01-01T15:49:11.242470Z","shell.execute_reply":"2023-01-01T15:49:11.241601Z","shell.execute_reply.started":"2023-01-01T15:49:06.397166Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on TPU  grpc://10.0.0.2:8470\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-01 15:49:06.405117: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2023-01-01 15:49:06.408248: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n","2023-01-01 15:49:06.408284: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n","2023-01-01 15:49:06.408387: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3f10461d28be): /proc/driver/nvidia/version does not exist\n","2023-01-01 15:49:06.411849: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-01-01 15:49:06.413718: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n","2023-01-01 15:49:06.448555: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-01 15:49:06.448617: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n","2023-01-01 15:49:06.466653: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-01 15:49:06.466710: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n","2023-01-01 15:49:06.468807: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n"]},{"name":"stdout","output_type":"stream","text":["REPLICAS:  8\n"]}],"source":["# Detect TPU, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy() \n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{},"source":["## Importing the data"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.243989Z","iopub.status.busy":"2023-01-01T15:49:11.243772Z","iopub.status.idle":"2023-01-01T15:49:11.635236Z","shell.execute_reply":"2023-01-01T15:49:11.634585Z","shell.execute_reply.started":"2023-01-01T15:49:11.243964Z"},"trusted":true},"outputs":[],"source":["GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.638412Z","iopub.status.busy":"2023-01-01T15:49:11.637638Z","iopub.status.idle":"2023-01-01T15:49:11.908973Z","shell.execute_reply":"2023-01-01T15:49:11.908061Z","shell.execute_reply.started":"2023-01-01T15:49:11.638371Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-01 15:49:11.646869: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-01 15:49:11.730358: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-01 15:49:11.807818: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"]}],"source":["EPOCHS = 100\n","BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n","\n","\n","IMAGE_SIZE = [192, 192]\n","GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-192x192'\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n","VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n","TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:11.911688Z","iopub.status.busy":"2023-01-01T15:49:11.911402Z","iopub.status.idle":"2023-01-01T15:49:12.097593Z","shell.execute_reply":"2023-01-01T15:49:12.096776Z","shell.execute_reply.started":"2023-01-01T15:49:11.911661Z"},"trusted":true},"outputs":[],"source":["def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n","    return image\n","\n","def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n","    }\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class'], tf.int32)\n","    return image, label # returns a dataset of (image, label) pairs\n","\n","def read_unlabeled_tfrecord(example):\n","    UNLABELED_TFREC_FORMAT = {\n","        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n","        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n","        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n","    }\n","    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    idnum = example['id']\n","    return image, idnum # returns a dataset of image(s)\n","\n","def load_dataset(filenames, labeled=True, ordered=False):\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False # disable order, increase speed\n","\n","    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n","    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset\n","\n","def get_training_dataset():\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","def get_validation_dataset():\n","    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=False)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    return dataset\n","\n","def get_test_dataset(ordered=False):\n","    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    return dataset\n","\n","training_dataset = get_training_dataset()\n","validation_dataset = get_validation_dataset()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:12.098955Z","iopub.status.busy":"2023-01-01T15:49:12.098755Z","iopub.status.idle":"2023-01-01T15:49:12.108471Z","shell.execute_reply":"2023-01-01T15:49:12.107617Z","shell.execute_reply.started":"2023-01-01T15:49:12.098932Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"]}],"source":["def count_data_items(filenames):\n","    # the number of data items is written in the name of the .tfrec\n","    # files, i.e. flowers00-230.tfrec = 230 data items\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n","    return np.sum(n)\n","\n","NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n","NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:49:33.738770Z","iopub.status.busy":"2023-01-01T15:49:33.738471Z","iopub.status.idle":"2023-01-01T15:49:36.926398Z","shell.execute_reply":"2023-01-01T15:49:36.925498Z","shell.execute_reply.started":"2023-01-01T15:49:33.738743Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data batch shape: (256, 192, 192, 3)\n","labels batch shape: (256,)\n"]}],"source":["for data_batch, labels_batch in training_dataset:\n","    print(\"data batch shape:\", data_batch.shape)\n","    \n","    print(\"labels batch shape:\", labels_batch.shape)\n","    break\n","    "]},{"cell_type":"markdown","metadata":{},"source":["## Architecturing the Deep Neural Network"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:55:11.173393Z","iopub.status.busy":"2023-01-01T15:55:11.172863Z","iopub.status.idle":"2023-01-01T15:55:12.687103Z","shell.execute_reply":"2023-01-01T15:55:12.685992Z","shell.execute_reply.started":"2023-01-01T15:55:11.173360Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_2 (InputLayer)            [(None, 192, 192, 3) 0                                            \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 192, 192, 32) 2400        input_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 192, 192, 32) 128         conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","activation_12 (Activation)      (None, 192, 192, 32) 0           batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_6 (MaxPooling2D)  (None, 96, 96, 32)   0           activation_12[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 96, 96, 32)   25600       max_pooling2d_6[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 96, 96, 32)   128         conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","activation_13 (Activation)      (None, 96, 96, 32)   0           batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_7 (MaxPooling2D)  (None, 48, 48, 32)   0           activation_13[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 48, 48, 64)   18432       max_pooling2d_7[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_16 (BatchNo (None, 48, 48, 64)   256         conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","activation_14 (Activation)      (None, 48, 48, 64)   0           batch_normalization_16[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 48, 48, 64)   36864       activation_14[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_17 (BatchNo (None, 48, 48, 64)   256         conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","activation_15 (Activation)      (None, 48, 48, 64)   0           batch_normalization_17[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling2d_8 (MaxPooling2D)  (None, 24, 24, 64)   0           activation_15[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 24, 24, 128)  73728       max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","batch_normalization_18 (BatchNo (None, 24, 24, 128)  512         conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","activation_16 (Activation)      (None, 24, 24, 128)  0           batch_normalization_18[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 24, 24, 128)  147456      activation_16[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_19 (BatchNo (None, 24, 24, 128)  512         conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 12, 12, 128)  8192        max_pooling2d_8[0][0]            \n","__________________________________________________________________________________________________\n","activation_17 (Activation)      (None, 24, 24, 128)  0           batch_normalization_19[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_20 (BatchNo (None, 12, 12, 128)  512         conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_9 (MaxPooling2D)  (None, 12, 12, 128)  0           activation_17[0][0]              \n","__________________________________________________________________________________________________\n","add_3 (Add)                     (None, 12, 12, 128)  0           batch_normalization_20[0][0]     \n","                                                                 max_pooling2d_9[0][0]            \n","__________________________________________________________________________________________________\n","dropout_3 (Dropout)             (None, 12, 12, 128)  0           add_3[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 12, 12, 256)  294912      dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_21 (BatchNo (None, 12, 12, 256)  1024        conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","activation_18 (Activation)      (None, 12, 12, 256)  0           batch_normalization_21[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 12, 12, 512)  1179648     activation_18[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_22 (BatchNo (None, 12, 12, 512)  2048        conv2d_23[0][0]                  \n","__________________________________________________________________________________________________\n","activation_19 (Activation)      (None, 12, 12, 512)  0           batch_normalization_22[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_24 (Conv2D)              (None, 12, 12, 256)  1179648     activation_19[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_23 (BatchNo (None, 12, 12, 256)  1024        conv2d_24[0][0]                  \n","__________________________________________________________________________________________________\n","activation_20 (Activation)      (None, 12, 12, 256)  0           batch_normalization_23[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_25 (Conv2D)              (None, 6, 6, 256)    32768       dropout_3[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_10 (MaxPooling2D) (None, 6, 6, 256)    0           activation_20[0][0]              \n","__________________________________________________________________________________________________\n","add_4 (Add)                     (None, 6, 6, 256)    0           conv2d_25[0][0]                  \n","                                                                 max_pooling2d_10[0][0]           \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 6, 6, 256)    0           add_4[0][0]                      \n","__________________________________________________________________________________________________\n","conv2d_26 (Conv2D)              (None, 6, 6, 512)    1179648     dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_24 (BatchNo (None, 6, 6, 512)    2048        conv2d_26[0][0]                  \n","__________________________________________________________________________________________________\n","activation_21 (Activation)      (None, 6, 6, 512)    0           batch_normalization_24[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_27 (Conv2D)              (None, 6, 6, 512)    2359296     activation_21[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_25 (BatchNo (None, 6, 6, 512)    2048        conv2d_27[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_28 (Conv2D)              (None, 3, 3, 512)    131072      dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","activation_22 (Activation)      (None, 6, 6, 512)    0           batch_normalization_25[0][0]     \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 3, 3, 512)    2048        conv2d_28[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_11 (MaxPooling2D) (None, 3, 3, 512)    0           activation_22[0][0]              \n","__________________________________________________________________________________________________\n","add_5 (Add)                     (None, 3, 3, 512)    0           batch_normalization_26[0][0]     \n","                                                                 max_pooling2d_11[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_29 (Conv2D)              (None, 3, 3, 1024)   4718592     add_5[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 3, 3, 1024)   4096        conv2d_29[0][0]                  \n","__________________________________________________________________________________________________\n","activation_23 (Activation)      (None, 3, 3, 1024)   0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","global_average_pooling2d_1 (Glo (None, 1024)         0           activation_23[0][0]              \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0] \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 104)          106600      dropout_5[0][0]                  \n","==================================================================================================\n","Total params: 11,511,496\n","Trainable params: 11,503,176\n","Non-trainable params: 8,320\n","__________________________________________________________________________________________________\n","None\n"]}],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","data_augmentation = keras.Sequential(\n","    [\n","        tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n","        layers.experimental.preprocessing.RandomRotation(0.1),\n","        layers.experimental.preprocessing.RandomZoom(0.1),\n","    ]\n",")\n","\n","\n","with strategy.scope():\n","\n","    def conv_layer_with_batch_norm(filter_size, kernel_size=3):\n","        global x\n","        x = layers.Conv2D(filters=filter_size,\n","                          kernel_size=kernel_size,\n","                          use_bias=False,\n","                          padding='same')(x)\n","        x = layers.BatchNormalization()(x)\n","        x = layers.Activation('relu')(x)\n","        return x\n","\n","    \n","    \n","    inputs = keras.Input(shape=[*IMAGE_SIZE, 3])\n","#     x = data_augmentation(inputs)\n","    x=inputs\n","\n","    x = conv_layer_with_batch_norm(32, kernel_size=5)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","    x = conv_layer_with_batch_norm(32, kernel_size=5)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","\n","    x = conv_layer_with_batch_norm(64, kernel_size=3)\n","    x = conv_layer_with_batch_norm(64, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","    residual = x\n","    x = conv_layer_with_batch_norm(128, kernel_size=3)\n","    x = conv_layer_with_batch_norm(128, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(128, 1, strides=(2, 2), use_bias=False)(residual)\n","    residual = layers.BatchNormalization()(residual)\n","    x = layers.Add()([residual, x])\n","\n","    x = layers.Dropout(0.2)(x)\n","\n","    residual = x\n","    x = conv_layer_with_batch_norm(256, kernel_size=3)\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = conv_layer_with_batch_norm(256, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(256, 1, strides=(2, 2), use_bias=False)(residual)\n","    x = layers.Add()([residual, x])\n","\n","    x = layers.Dropout(0.3)(x)\n","    residual = x\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(512, 1, strides=(2, 2), use_bias=False)(residual)\n","    residual = layers.BatchNormalization()(residual)\n","    x = layers.Add()([residual, x])\n","\n","    x = conv_layer_with_batch_norm(1024, kernel_size=3)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(104, activation='softmax')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","    \n","\n","print(model.summary())\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-01T15:55:15.989465Z","iopub.status.busy":"2023-01-01T15:55:15.989131Z"},"trusted":true},"outputs":[],"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n","              metrics=['sparse_categorical_accuracy', ])\n","\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                     patience=10,\n","                                     restore_best_weights=True),\n","    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n","                                         factor=0.9,\n","                                         patience=2,\n","                                         verbose=1)\n","]\n","\n","history = model.fit(training_dataset,\n","                    validation_data=validation_dataset,\n","                    epochs=EPOCHS,\n","                    steps_per_epoch=STEPS_PER_EPOCH,\n","                    workers=4,\n","                    callbacks=callbacks)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.15 ('tensorflow')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"778c362588975e4261519a1bde36f5390c14a0d91b7c2cecfd2d877161f6dd0d"}}},"nbformat":4,"nbformat_minor":4}
