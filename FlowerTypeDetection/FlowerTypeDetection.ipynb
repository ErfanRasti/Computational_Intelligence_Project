{"cells":[{"cell_type":"markdown","metadata":{"editable":false},"source":["# Flower Type Detection"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Downloading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from google.colab import files\n","# files.upload()\n","\n","# ! mkdir -p ~/.kaggle\n","# ! cp kaggle.json ~/.kaggle/\n","# ! chmod 600 ~/.kaggle/kaggle.json\n","\n","\n","# ! kaggle competitions download -c tpu-getting-started\n","# ! mkdir data/\n","# ! unzip tpu-getting-started.zip -d ./data/tpu-getting-started\n","\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":86,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:48:23.773507Z","iopub.status.busy":"2023-01-10T13:48:23.773245Z","iopub.status.idle":"2023-01-10T13:48:23.781252Z","shell.execute_reply":"2023-01-10T13:48:23.778998Z","shell.execute_reply.started":"2023-01-10T13:48:23.773482Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version 2.4.1\n"]}],"source":["import re\n","import os\n","import pathlib\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","MODELS_DIR = pathlib.Path('./models/')\n","\n","print(\"Tensorflow version \" + tf.__version__)\n"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Setting up the TPU"]},{"cell_type":"code","execution_count":87,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:48:23.785094Z","iopub.status.busy":"2023-01-10T13:48:23.784740Z","iopub.status.idle":"2023-01-10T13:48:28.871130Z","shell.execute_reply":"2023-01-10T13:48:28.869657Z","shell.execute_reply.started":"2023-01-10T13:48:23.785066Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on TPU  grpc://10.0.0.2:8470\n"]},{"name":"stderr","output_type":"stream","text":["2023-01-10 13:48:23.791795: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-10 13:48:23.791895: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n","2023-01-10 13:48:23.795996: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n","2023-01-10 13:48:23.796074: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n"]},{"name":"stdout","output_type":"stream","text":["REPLICAS:  8\n"]}],"source":["# Detect TPU, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n","    print('Running on TPU ', tpu.master())\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy() \n","\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Importing the data"]},{"cell_type":"code","execution_count":88,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:48:28.873015Z","iopub.status.busy":"2023-01-10T13:48:28.872678Z","iopub.status.idle":"2023-01-10T13:48:29.229671Z","shell.execute_reply":"2023-01-10T13:48:29.228368Z","shell.execute_reply.started":"2023-01-10T13:48:28.872976Z"},"trusted":true},"outputs":[],"source":["GCS_DS_PATH = './data/tpu-getting-started'"]},{"cell_type":"code","execution_count":89,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:48:29.231722Z","iopub.status.busy":"2023-01-10T13:48:29.231424Z","iopub.status.idle":"2023-01-10T13:48:29.366469Z","shell.execute_reply":"2023-01-10T13:48:29.365585Z","shell.execute_reply.started":"2023-01-10T13:48:29.231673Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-01-10 13:48:29.234765: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-10 13:48:29.278563: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","2023-01-10 13:48:29.321042: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n"]}],"source":["EPOCHS = 100\n","BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n","\n","\n","IMAGE_SIZE = [512, 512]\n","GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n","AUTO = tf.data.experimental.AUTOTUNE\n","\n","TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n","VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n","TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec')\n"]},{"cell_type":"code","execution_count":99,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:51:44.256044Z","iopub.status.busy":"2023-01-10T13:51:44.255652Z","iopub.status.idle":"2023-01-10T13:51:44.420355Z","shell.execute_reply":"2023-01-10T13:51:44.419053Z","shell.execute_reply.started":"2023-01-10T13:51:44.256016Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n"]}],"source":["def decode_image(image_data):\n","    image = tf.image.decode_jpeg(image_data, channels=3)\n","    # convert image to floats in [0, 1] range\n","    image = tf.cast(image, tf.float32) / 255.0\n","    image = tf.reshape(image, [*IMAGE_SIZE, 3])  # explicit size needed for TPU\n","    return image\n","\n","\n","def read_labeled_tfrecord(example):\n","    LABELED_TFREC_FORMAT = {\n","        # tf.string means bytestring\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        # shape [] means single element\n","        \"class\": tf.io.FixedLenFeature([], tf.int64),\n","    }\n","    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    label = tf.cast(example['class'], tf.int32)\n","    return image, label  # returns a dataset of (image, label) pairs\n","\n","\n","def read_unlabeled_tfrecord(example):\n","    UNLABELED_TFREC_FORMAT = {\n","        # tf.string means bytestring\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        # shape [] means single element\n","        \"id\": tf.io.FixedLenFeature([], tf.string),\n","        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n","    }\n","    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n","    image = decode_image(example['image'])\n","    idnum = example['id']\n","    return image, idnum  # returns a dataset of image(s)\n","\n","\n","def load_dataset(filenames, labeled=True, ordered=False):\n","    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n","    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n","\n","    ignore_order = tf.data.Options()\n","    if not ordered:\n","        ignore_order.experimental_deterministic = False  # disable order, increase speed\n","\n","    # automatically interleaves reads from multiple files\n","    dataset = tf.data.TFRecordDataset(filenames)\n","    # uses data as soon as it streams in, rather than in its original order\n","    dataset = dataset.with_options(ignore_order)\n","    dataset = dataset.map(\n","        read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n","    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n","    return dataset\n","\n","\n","def data_augment(image, label):\n","    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n","    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n","    # of the TPU while the TPU itself is computing gradients.\n","    image = tf.image.random_flip_left_right(image)\n","    image = tf.image.random_flip_up_down(image)\n","    image = tf.image.random_saturation(image, 0, 2)\n","    image = tf.image.random_brightness(image, 0.2)\n","    image = tf.keras.image.random_zoom(image, 0.1)\n","    image = tf.image.random_contrast(image, 0.1, 0.2)\n","    return image, label\n","\n","\n","def get_training_dataset():\n","    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n","    # dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n","    dataset = dataset.repeat()  # the training dataset must repeat for several epochs\n","    dataset = dataset.shuffle(2048)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    # prefetch next batch while training (autotune prefetch buffer size)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","\n","def get_validation_dataset(ordered=False):\n","    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","\n","def get_test_dataset(ordered=False):\n","    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(AUTO)\n","    return dataset\n","\n","\n","def count_data_items(filenames):\n","    # the number of data items is written in the name of the .tfrec\n","    # files, i.e. flowers00-230.tfrec = 230 data items\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1))\n","         for filename in filenames]\n","    return np.sum(n)\n","\n","\n","NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n","NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n","NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n","STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n","print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(\n","    NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n","\n","\n","training_dataset = get_training_dataset()\n","validation_dataset = get_validation_dataset()\n"]},{"cell_type":"code","execution_count":101,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2023-01-10T13:51:46.926395Z","iopub.status.busy":"2023-01-10T13:51:46.926013Z","iopub.status.idle":"2023-01-10T13:51:55.955665Z","shell.execute_reply":"2023-01-10T13:51:55.954835Z","shell.execute_reply.started":"2023-01-10T13:51:46.926354Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["data batch shape: (128, 512, 512, 3)\n","labels batch shape: (128,)\n"]}],"source":["for data_batch, labels_batch in training_dataset:\n","    print(\"data batch shape:\", data_batch.shape)\n","    \n","    print(\"labels batch shape:\", labels_batch.shape)\n","    break\n","    "]},{"cell_type":"markdown","metadata":{"editable":false},"source":["## Architecturing the Deep Neural Network"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# data_augmentation = keras.Sequential(\n","#     [\n","#         tf.keras.RandomFlip(\n","#             \"horizontal_and_vertical\"),\n","#         layers..RandomRotation(0.1),\n","#         layers.RandomZoom(0.1),\n","#     ]\n","# )\n","\n","\n","with strategy.scope():\n","\n","    inputs = keras.Input(shape=[*IMAGE_SIZE, 3])\n","#     x = data_augmentation(inputs)\n","    x = inputs\n","#     x = layers.Rescaling(1. / 255)(x)\n","\n","    x = layers.Conv2D(filters=32, kernel_size=5,\n","                      use_bias=False, padding='same')(x)\n","\n","    def conv_layer_with_batch_norm(filter_size, kernel_size=3):\n","        global x\n","        x = layers.Conv2D(filters=filter_size,\n","                          kernel_size=kernel_size,\n","                          use_bias=False,\n","                          padding='same')(x)\n","        x = layers.BatchNormalization()(x)\n","        x = layers.Activation('relu')(x)\n","        return x\n","\n","    x = conv_layer_with_batch_norm(32, kernel_size=5)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","    x = conv_layer_with_batch_norm(32, kernel_size=5)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","    x = conv_layer_with_batch_norm(64, kernel_size=3)\n","    x = conv_layer_with_batch_norm(64, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","\n","    residual = x\n","    x = conv_layer_with_batch_norm(128, kernel_size=3)\n","    x = conv_layer_with_batch_norm(128, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(128, 1, strides=(2, 2), use_bias=False)(residual)\n","    residual = layers.BatchNormalization()(residual)\n","    x = layers.Add()([residual, x])\n","\n","    residual = x\n","    x = conv_layer_with_batch_norm(256, kernel_size=3)\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = conv_layer_with_batch_norm(256, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(256, 1, strides=(2, 2), use_bias=False)(residual)\n","    x = layers.Add()([residual, x])\n","\n","    x = layers.Dropout(0.25)(x)\n","\n","    residual = x\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n","    residual = layers.Conv2D(512, 1, strides=(2, 2), use_bias=False)(residual)\n","    residual = layers.BatchNormalization()(residual)\n","    x = layers.Add()([residual, x])\n","\n","    x = conv_layer_with_batch_norm(512, kernel_size=3)\n","\n","    x = layers.GlobalAveragePooling2D()(x)\n","\n","    x = layers.Dropout(0.5)(x)\n","    outputs = layers.Dense(104, activation='softmax')(x)\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","\n","print(model.summary())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['sparse_categorical_accuracy', ])\n","\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n","                                     patience=10,\n","                                     restore_best_weights=True),\n","        keras.callbacks.ModelCheckpoint(\n","        filepath=\n","        os.path.join(MODELS_DIR, 'modern_arch_ERS.keras'),\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","\n","history = model.fit(training_dataset,\n","                    validation_data=validation_dataset,\n","                    epochs=EPOCHS,\n","                    steps_per_epoch=STEPS_PER_EPOCH,\n","                    workers=4,\n","                    callbacks=callbacks)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Evaluting the model"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false},"outputs":[],"source":["# since we are splitting the dataset and iterating separately on images and ids, order matters.\n","test_ds = get_test_dataset(ordered=True)\n","\n","print('Computing predictions...')\n","test_images_ds = test_ds.map(lambda image, idnum: image)\n","probabilities = model.predict(test_images_ds)\n","predictions = np.argmax(probabilities, axis=-1)\n","print(predictions)\n","\n","print('Generating submission.csv file...')\n","test_ids_ds = test_ds.map(lambda image, idnum: idnum).unbatch()\n","test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))\n","                ).numpy().astype('U')  # all in one batch\n","np.savetxt('submission.csv', np.rec.fromarrays([test_ids, predictions]), fmt=[\n","           '%s', '%d'], delimiter=',', header='id,label', comments='')\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15 (main, Nov 24 2022, 14:31:59) \n[GCC 11.2.0]"},"vscode":{"interpreter":{"hash":"778c362588975e4261519a1bde36f5390c14a0d91b7c2cecfd2d877161f6dd0d"}}},"nbformat":4,"nbformat_minor":4}
