{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"778c362588975e4261519a1bde36f5390c14a0d91b7c2cecfd2d877161f6dd0d"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Flower Type Detection","metadata":{"editable":false}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"editable":false}},{"cell_type":"code","source":"! pip3 install -U tensorflow==2.9\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:11.926648Z","iopub.execute_input":"2023-01-10T13:48:11.927465Z","iopub.status.idle":"2023-01-10T13:48:19.117741Z","shell.execute_reply.started":"2023-01-10T13:48:11.927438Z","shell.execute_reply":"2023-01-10T13:48:19.116621Z"},"editable":false,"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.9 in /opt/conda/lib/python3.7/site-packages (2.9.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.32.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (2.10.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (21.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.1.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (0.29.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (15.0.6.1)\nRequirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (2.9.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.15.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.12.1)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (0.3.3)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.6.3)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.21.6)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.3.0)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (3.18.0)\nRequirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (2.9.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (57.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (3.7.4.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.1.0)\nRequirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (1.12)\nRequirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.9) (2.9.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow==2.9) (0.37.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (0.4.5)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (1.34.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (3.3.4)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.25.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (1.8.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9) (2.0.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (4.2.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (1.3.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.4.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9) (0.4.8)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (2021.5.30)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9) (1.26.6)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9) (3.5.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow==2.9) (2.4.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# !  python3 -c \"import tensorflow as tf; print(tf.__version__)\"\n! python3 -c \"import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))\"\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:19.121813Z","iopub.execute_input":"2023-01-10T13:48:19.122208Z","iopub.status.idle":"2023-01-10T13:48:23.770974Z","shell.execute_reply.started":"2023-01-10T13:48:19.122173Z","shell.execute_reply":"2023-01-10T13:48:23.769205Z"},"editable":false,"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"2023-01-10 13:48:19.612740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-10 13:48:19.612803: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-01-10 13:48:22.983442: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-01-10 13:48:22.983499: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n2023-01-10 13:48:22.983519: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ad04239be9e0): /proc/driver/nvidia/version does not exist\n[]\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom kaggle_datasets import KaggleDatasets\nprint(\"Tensorflow version \" + tf.__version__)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:23.773245Z","iopub.execute_input":"2023-01-10T13:48:23.773507Z","iopub.status.idle":"2023-01-10T13:48:23.781252Z","shell.execute_reply.started":"2023-01-10T13:48:23.773482Z","shell.execute_reply":"2023-01-10T13:48:23.778998Z"},"editable":false,"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Tensorflow version 2.4.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Setting up the TPU","metadata":{"editable":false}},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() \n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:23.784740Z","iopub.execute_input":"2023-01-10T13:48:23.785094Z","iopub.status.idle":"2023-01-10T13:48:28.871130Z","shell.execute_reply.started":"2023-01-10T13:48:23.785066Z","shell.execute_reply":"2023-01-10T13:48:28.869657Z"},"editable":false,"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Running on TPU  grpc://10.0.0.2:8470\n","output_type":"stream"},{"name":"stderr","text":"2023-01-10 13:48:23.791795: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-10 13:48:23.791895: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n2023-01-10 13:48:23.795996: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-01-10 13:48:23.796074: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30021}\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS:  8\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing the data","metadata":{"editable":false}},{"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:28.872678Z","iopub.execute_input":"2023-01-10T13:48:28.873015Z","iopub.status.idle":"2023-01-10T13:48:29.229671Z","shell.execute_reply.started":"2023-01-10T13:48:28.872976Z","shell.execute_reply":"2023-01-10T13:48:29.228368Z"},"editable":false,"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\n\nIMAGE_SIZE = [512, 512]\nGCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\nAUTO = tf.data.experimental.AUTOTUNE\n\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\nVALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\nTEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:29.231424Z","iopub.execute_input":"2023-01-10T13:48:29.231722Z","iopub.status.idle":"2023-01-10T13:48:29.366469Z","shell.execute_reply.started":"2023-01-10T13:48:29.231673Z","shell.execute_reply":"2023-01-10T13:48:29.365585Z"},"editable":false,"trusted":true},"execution_count":89,"outputs":[{"name":"stderr","text":"2023-01-10 13:48:29.234765: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n2023-01-10 13:48:29.278563: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n2023-01-10 13:48:29.321042: I tensorflow/core/platform/cloud/google_auth_provider.cc:180] Attempting an empty bearer token since no token was retrieved from files, and GCE metadata check was skipped.\n","output_type":"stream"}]},{"cell_type":"code","source":"BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:48:29.367549Z","iopub.execute_input":"2023-01-10T13:48:29.367740Z","iopub.status.idle":"2023-01-10T13:48:29.374893Z","shell.execute_reply.started":"2023-01-10T13:48:29.367717Z","shell.execute_reply":"2023-01-10T13:48:29.372837Z"},"editable":false,"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"128"},"metadata":{}}]},{"cell_type":"code","source":"def decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    label = tf.cast(example['class'], tf.int32)\n    return image, label # returns a dataset of (image, label) pairs\n\ndef read_unlabeled_tfrecord(example):\n    UNLABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n    }\n    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    idnum = example['id']\n    return image, idnum # returns a dataset of image(s)\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(filenames) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\n# def get_training_dataset():\n#     dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n#     dataset = dataset.repeat() # the training dataset must repeat for several epochs\n#     dataset = dataset.shuffle(2048)\n#     dataset = dataset.batch(BATCH_SIZE)\n#     return dataset\n\n# def get_validation_dataset():\n#     dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=False)\n#     dataset = dataset.batch(BATCH_SIZE)\n#     dataset = dataset.cache()\n#     return dataset\n\n# def get_test_dataset(ordered=False):\n#     dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n#     dataset = dataset.batch(BATCH_SIZE)\n#     return dataset\n\ndef data_augment(image, label):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_saturation(image, 0, 2)\n    image = tf.image.random_brightness(image, 0.2)\n#     image = tf.keras.preprocessing.image.random_zoom(image, 0.1)\n#     image = tf.image.random_contrast(image, 0.1, 0.2)\n    return image, label\n  \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\ndef count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec\n    # files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\nNUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\nprint('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n\n\ntraining_dataset = get_training_dataset()\nvalidation_dataset = get_validation_dataset()","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:51:44.255652Z","iopub.execute_input":"2023-01-10T13:51:44.256044Z","iopub.status.idle":"2023-01-10T13:51:44.420355Z","shell.execute_reply.started":"2023-01-10T13:51:44.256016Z","shell.execute_reply":"2023-01-10T13:51:44.419053Z"},"editable":false,"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Dataset: 12753 training images, 3712 validation images, 7382 unlabeled test images\n","output_type":"stream"}]},{"cell_type":"code","source":"# def count_data_items(filenames):\n#     # the number of data items is written in the name of the .tfrec\n#     # files, i.e. flowers00-230.tfrec = 230 data items\n#     n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n#     return np.sum(n)\n\n# NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n# NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n# NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n# STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\n# print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:51:45.262687Z","iopub.execute_input":"2023-01-10T13:51:45.263788Z","iopub.status.idle":"2023-01-10T13:51:45.268753Z","shell.execute_reply.started":"2023-01-10T13:51:45.263719Z","shell.execute_reply":"2023-01-10T13:51:45.267938Z"},"editable":false,"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"for data_batch, labels_batch in training_dataset:\n    print(\"data batch shape:\", data_batch.shape)\n    \n    print(\"labels batch shape:\", labels_batch.shape)\n    break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-10T13:51:46.926013Z","iopub.execute_input":"2023-01-10T13:51:46.926395Z","iopub.status.idle":"2023-01-10T13:51:55.955665Z","shell.execute_reply.started":"2023-01-10T13:51:46.926354Z","shell.execute_reply":"2023-01-10T13:51:55.954835Z"},"editable":false,"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"data batch shape: (128, 512, 512, 3)\nlabels batch shape: (128,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Architecturing the Deep Neural Network","metadata":{"editable":false}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# data_augmentation = keras.Sequential(\n#     [\n#         tf.keras.layers.experimental.preprocessing.RandomFlip(\n#             \"horizontal_and_vertical\"),\n#         layers.experimental.preprocessing.RandomRotation(0.1),\n#         layers.experimental.preprocessing.RandomZoom(0.1),\n#     ]\n# )\n\n\nwith strategy.scope():\n\n    inputs = keras.Input(shape=[*IMAGE_SIZE, 3])\n#     x = data_augmentation(inputs)\n    x = inputs\n#     x = layers.Rescaling(1. / 255)(x)\n\n    x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False, padding='same')(x) \n\n\n    def conv_layer_with_batch_norm(filter_size, kernel_size=3):\n        global x\n        x = layers.SeparableConv2D(filters=filter_size,\n                          kernel_size=kernel_size,\n                          use_bias=False,\n                          padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation('relu')(x)\n        return x\n\n\n\n    x = conv_layer_with_batch_norm(32, kernel_size=5)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n\n    x = conv_layer_with_batch_norm(32, kernel_size=5)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n\n\n    x = conv_layer_with_batch_norm(64, kernel_size=3)\n    x = conv_layer_with_batch_norm(64, kernel_size=3)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n\n    residual = x\n    x = conv_layer_with_batch_norm(128, kernel_size=3)\n    x = conv_layer_with_batch_norm(128, kernel_size=3)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    residual = layers.Conv2D(128, 1, strides=(2, 2), use_bias=False)(residual)\n    residual = layers.BatchNormalization()(residual)\n    x = layers.Add()([residual, x])\n\n    residual = x\n    x = conv_layer_with_batch_norm(256, kernel_size=3)\n    x = conv_layer_with_batch_norm(512, kernel_size=3)\n    x = conv_layer_with_batch_norm(256, kernel_size=3)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    residual = layers.Conv2D(256, 1, strides=(2, 2), use_bias=False)(residual)\n    x = layers.Add()([residual, x])\n\n    x = layers.Dropout(0.2)(x)\n\n    \n    residual = x\n    x = conv_layer_with_batch_norm(512, kernel_size=3)\n    x = conv_layer_with_batch_norm(512, kernel_size=3)\n    x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    residual = layers.Conv2D(512, 1, strides=(2, 2), use_bias=False)(residual)\n    residual = layers.BatchNormalization()(residual)\n    x = layers.Add()([residual, x])\n    \n#     residual = x\n#     x = conv_layer_with_batch_norm(1024, kernel_size=3)\n#     x = conv_layer_with_batch_norm(1024, kernel_size=3)\n#     x = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n#     residual = layers.Conv2D(1024, 1, strides=(2, 2), use_bias=False)(residual)\n#     residual = layers.BatchNormalization()(residual)\n#     x = layers.Add()([residual, x])\n\n        \n    x = conv_layer_with_batch_norm(512, kernel_size=3)\n\n\n    x = layers.GlobalAveragePooling2D()(x)\n\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(104, activation='softmax')(x)\n\n    model = keras.Model(inputs=inputs, outputs=outputs)\n\n\nprint(model.summary())\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='sparse_categorical_crossentropy',\n              optimizer='rmsprop',\n              metrics=['sparse_categorical_accuracy', ])\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n                                     patience=10,\n                                     restore_best_weights=True),\n#     tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n#                                          factor=0.9,\n#                                          patience=2,\n#                                          verbose=1)\n]\n\nhistory = model.fit(training_dataset,\n                    validation_data=validation_dataset,\n                    epochs=EPOCHS,\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    workers=4,\n                    callbacks=callbacks)\n","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]}]}